{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model for predicting period return class (1-10)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import joblib\n",
    "  \n",
    "   \n",
    "\n",
    "def getData(df, target):\n",
    "\n",
    "    data = df.drop(columns = ['open', 'high', 'low', 'close', 'volume'])\n",
    "    data.dropna(how='any', inplace=True)\n",
    "    features = [c for c in data.columns if \"return\" not in c]\n",
    "    X = data[features]\n",
    "    y = data[['timestamp', target]]\n",
    "    X.head()\n",
    "\n",
    "    X.reset_index(inplace=True)\n",
    "    X.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    y.reset_index(inplace=True)\n",
    "    y.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "    timestamps = X['timestamp'].values  # Extract timestamp\n",
    "    features = X.drop(columns=['timestamp'])\n",
    "\n",
    "    # Step 2: Apply StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Step 3: Combine the scaled features with the timestamp\n",
    "    scaled_df = pd.DataFrame(scaled_features)\n",
    "\n",
    "    scaled_df = pd.concat([y[target], scaled_df], axis=1)\n",
    "    scaled_df = pd.concat([X['timestamp'], scaled_df], axis=1)\n",
    "\n",
    "    # Use qcut to divide 'returns' into 11 equal-sized groups and label them from 1 to 11\n",
    "    scaled_df['return_group'] = pd.qcut(scaled_df[target], q=11, labels=range(1, 11 + 1))\n",
    "\n",
    "\n",
    "\n",
    "    train_size = 0.8  # 80% for training and 20% for testing\n",
    "\n",
    "    split_index = int(len(scaled_df) * train_size)\n",
    "\n",
    "    train_df = scaled_df[:split_index]\n",
    "    test_df = scaled_df[split_index:]\n",
    "\n",
    "    X_train = train_df.drop(columns=[target, 'return_group']).to_numpy()\n",
    "    y_train = train_df[['timestamp','return_group']].to_numpy()\n",
    "\n",
    "    X_test = test_df.drop(columns=[target, 'return_group']).to_numpy()\n",
    "    y_test = test_df[['timestamp','return_group']].to_numpy()\n",
    "\n",
    "    TRAIN_TIMESTAMPS = X_train[:, 0]\n",
    "\n",
    "    TEST_TIMESTAMPS = X_test[:, 0]\n",
    "\n",
    "    #remove timestamps\n",
    "    X_train = X_train[:, 1:]\n",
    "    y_train = y_train[:, 1:].flatten()\n",
    "\n",
    "    X_test = X_test[:, 1:]\n",
    "    y_test = y_test[:, 1:].flatten()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def getReports(y_test, y_pred, model_name, resid=None, output_folder='visualizations'):\n",
    "\n",
    "    output_folder = f\"{output_folder}/random-forest/{model_name}\" \n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Calculate accuracy for Random Forest\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "    print(f'Random Forest Accuracy: {accuracy_rf:.2f}')\n",
    "\n",
    "    # Generate confusion matrix for Random Forest\n",
    "    conf_matrix_rf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Classification report for Random Forest\n",
    "    class_report_rf = classification_report(y_test, y_pred)\n",
    "    print(\"Random Forest Classification Report:\\n\", class_report_rf)\n",
    "\n",
    "    # Plotting confusion matrix for Random Forest\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.title(\"Random Forest Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(os.path.join(output_folder, 'confusion_matrix_rf.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Generate classification report as a DataFrame for visualization\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    class_labels = [key for key in class_report.keys() if key not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "    precision = [class_report[label]['precision'] for label in class_labels]\n",
    "    recall = [class_report[label]['recall'] for label in class_labels]\n",
    "    f1 = [class_report[label]['f1-score'] for label in class_labels]\n",
    "\n",
    "    # Create a DataFrame for the classification report\n",
    "    class_report_df = pd.DataFrame({\n",
    "        'Class': class_labels,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    class_report_df.set_index('Class', inplace=True)\n",
    "\n",
    "    # Plotting the classification report\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    class_report_df.plot(kind='bar', alpha=0.75, ax=plt.gca())\n",
    "    plt.title(\"Classification Report\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(output_folder, 'classification_report.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Plotting the distribution of 'returns'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(y_pred, kde=True, bins=30, color='skyblue')\n",
    "    plt.title(\"Distribution of 'Returns'\")\n",
    "    plt.xlabel(\"Returns\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.savefig(os.path.join(output_folder, 'distribution_returns.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate correct group prediction accuracy\n",
    "    correct_predictions = (y_pred == y_test).sum()\n",
    "    total_predictions = len(y_test)\n",
    "    accuracy_group = correct_predictions / total_predictions\n",
    "    print(f\"Correct Group Prediction Accuracy: {accuracy_group:.2f}\")\n",
    "\n",
    "    # Plotting the distribution of 'resid' if provided\n",
    "    if resid is not None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(resid, kde=True, bins=30, color='skyblue')\n",
    "        plt.title(\"Distribution of Residuals\")\n",
    "        plt.xlabel(\"Residual Values\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.axvline(x=resid.mean(), color='r', linestyle='--', label='Mean')\n",
    "        plt.axvline(x=resid.median(), color='g', linestyle='--', label='Median')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_folder, 'distribution_residuals.png'), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "class rfModel:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, ticker, frequency, target, timestamps, model_name):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.ticker = ticker\n",
    "        self.frequency = frequency\n",
    "        self.target = target\n",
    "        self.timestamps = timestamps\n",
    "        self.model_name = model_name\n",
    "\n",
    "    # def fitModelAndPredict(self):\n",
    "    #     # # Set up MLflow tracking\n",
    "    \n",
    "\n",
    "    # # Initialize and fit the model\n",
    "    #     self.model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    #     self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    #     # Predict and evaluate for Random Forest\n",
    "    #     self.y_pred = self.model.predict(self.X_test)\n",
    "    #     accuracy_rf = accuracy_score(self.y_test, self.y_pred)\n",
    "\n",
    "    #     # Create a model directory\n",
    "    #     model_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "    #     model_name = f\"{self.ticker}_{self.frequency}_{self.target}_{model_date}\"\n",
    "    #     model_dir = f\"models/random-forest/{model_name}\"\n",
    "\n",
    "    #     # Ensure the directory exists\n",
    "    #     os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    #     # Save the model as a .joblib file\n",
    "    #     model_path = os.path.join(model_dir, f\"{model_name}.joblib\")\n",
    "    #     joblib.dump(self.model, model_path)\n",
    "\n",
    "    #     # Log model and metrics with MLflow\n",
    "    #     mlflow.log_param(\"ticker\", self.ticker)\n",
    "    #     mlflow.log_param(\"frequency\", self.frequency)\n",
    "    #     mlflow.log_param(\"target\", self.target)\n",
    "    #     mlflow.log_param(\"model_date\", model_date)\n",
    "    #     mlflow.log_metric(\"accuracy\", accuracy_rf)\n",
    "\n",
    "    #     # Save metrics and classification report as a text file\n",
    "    #     metrics_path = os.path.join(model_dir, \"metrics.txt\")\n",
    "    #     with open(metrics_path, \"w\") as f:\n",
    "    #         f.write(f\"Random Forest Accuracy: {accuracy_rf}\\n\")\n",
    "    #         f.write(\"Classification Report:\\n\")\n",
    "    #         f.write(classification_report(self.y_test, self.y_pred))\n",
    "\n",
    "    #     print(f'Random Forest Accuracy: {accuracy_rf}')\n",
    "    #     print(classification_report(self.y_test, self.y_pred))\n",
    "    def fitModelAndPredict(self):\n",
    "        # Initialize and fit the model\n",
    "        self.model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Predict and evaluate for Random Forest\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        accuracy_rf = accuracy_score(self.y_test, self.y_pred)\n",
    "\n",
    "        accuracy_rf = accuracy_score(self.y_test, self.y_pred)\n",
    "        # Log metrics with MLflow\n",
    "        # self.logMetrics(accuracy_rf)\n",
    "\n",
    "        # Save the model and metrics\n",
    "        self.saveModelAndMetrics(accuracy_rf)\n",
    "\n",
    "        print(f'Random Forest Accuracy: {accuracy_rf}')\n",
    "        print(classification_report(self.y_test, self.y_pred))\n",
    "\n",
    "    def logMetrics(self, accuracy_rf):\n",
    "        # Log parameters and metrics with MLflow\n",
    "        mlflow.log_param(\"ticker\", self.ticker)\n",
    "        mlflow.log_param(\"frequency\", self.frequency)\n",
    "        mlflow.log_param(\"target\", self.target)\n",
    "        mlflow.log_param(\"model_date\", datetime.now().date().strftime(\"%Y-%m-%d\"))\n",
    "        mlflow.log_metric(\"accuracy\", accuracy_rf)\n",
    "\n",
    "    def saveModelAndMetrics(self, accuracy_rf):\n",
    "        # Create a model directory\n",
    "        model_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "        model_name = f\"{self.ticker}_{self.frequency}_{self.target}_{model_date}\"\n",
    "        model_dir = f\"models/random-forest/{model_name}\"\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        # Save the model as a .joblib file\n",
    "        model_path = f\"{model_dir}/{model_name}.joblib\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        joblib.dump(self.model, model_path)\n",
    "\n",
    "        # Save metrics and classification report as a text file\n",
    "        metrics_path = os.path.join(model_dir, \"metrics.txt\")\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            f.write(f\"Random Forest Accuracy: {accuracy_rf}\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(classification_report(self.y_test, self.y_pred))\n",
    "\n",
    "\n",
    "    def setModel(self, model):\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # with mlflow.start_run():\n",
    "    #     mlflow.keras.log_model(rf.model, \"model\", signature=signature)\n",
    "    #     # Save the model locally\n",
    "    #     rf.model.save(f\"models/random-forest/{ticker}_{frq}_{target}_{model_date}.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_rf = accuracy_score(rf.y_test, rf.y_pred)\n",
    "# rf.saveModelAndMetrics(accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           timestamp     open     high      low    close    volume  \\\n",
      "0       1.710029e+09  68459.1  68491.1  68459.1  68490.3  0.813935   \n",
      "1       1.710029e+09  68485.9  68506.3  68485.9  68499.0  0.022906   \n",
      "2       1.710029e+09  68499.1  68499.1  68479.8  68479.8  0.077374   \n",
      "3       1.710029e+09  68469.5  68481.5  68463.0  68469.1  0.768665   \n",
      "4       1.710029e+09  68469.1  68481.9  68469.1  68470.8  5.705731   \n",
      "...              ...      ...      ...      ...      ...       ...   \n",
      "291421  1.727740e+09  63203.9  63268.4  63203.9  63263.9  4.582019   \n",
      "291422  1.727740e+09  63264.0  63287.0  63264.0  63287.0  2.031514   \n",
      "291423  1.727741e+09  63287.0  63300.0  63287.0  63300.0  0.737142   \n",
      "291424  1.727741e+09  63300.0  63315.3  63300.0  63306.0  0.317491   \n",
      "291425  1.727741e+09  63306.0  63338.5  63305.9  63338.5  0.336572   \n",
      "\n",
      "                   0             1          2             3  ...  \\\n",
      "0       1.710029e+09           NaN        NaN           NaN  ...   \n",
      "1       1.710029e+09           NaN        NaN           NaN  ...   \n",
      "2       1.710029e+09           NaN        NaN           NaN  ...   \n",
      "3       1.710029e+09           NaN        NaN           NaN  ...   \n",
      "4       1.710029e+09           NaN        NaN           NaN  ...   \n",
      "...              ...           ...        ...           ...  ...   \n",
      "291421  1.727740e+09  63340.589800  63138.330  62936.070200  ...   \n",
      "291422  1.727740e+09  63354.913069  63143.345  62931.776931  ...   \n",
      "291423  1.727741e+09  63367.847077  63147.535  62927.222923  ...   \n",
      "291424  1.727741e+09  63381.232386  63152.025  62922.817614  ...   \n",
      "291425  1.727741e+09  63404.301834  63161.080  62917.858166  ...   \n",
      "\n",
      "        hilberttransformdominantcycleperiod_1  \\\n",
      "0                                         NaN   \n",
      "1                                         NaN   \n",
      "2                                         NaN   \n",
      "3                                         NaN   \n",
      "4                                         NaN   \n",
      "...                                       ...   \n",
      "291421                              30.535926   \n",
      "291422                              29.436880   \n",
      "291423                              28.107984   \n",
      "291424                              26.796453   \n",
      "291425                              25.681133   \n",
      "\n",
      "        hilberttransformdominantcyclephase_1  hilberttransformtrendmode_1  \\\n",
      "0                                        NaN                          0.0   \n",
      "1                                        NaN                          0.0   \n",
      "2                                        NaN                          0.0   \n",
      "3                                        NaN                          0.0   \n",
      "4                                        NaN                          0.0   \n",
      "...                                      ...                          ...   \n",
      "291421                             47.004691                          0.0   \n",
      "291422                             65.385510                          1.0   \n",
      "291423                             83.057675                          0.0   \n",
      "291424                            103.593381                          0.0   \n",
      "291425                            126.243176                          0.0   \n",
      "\n",
      "        return_2n  return_4n  return_8n  return_16n  return_32n  return_64n  \\\n",
      "0       -0.000153  -0.000285  -0.000548   -0.000972   -0.000726    0.004021   \n",
      "1       -0.000437  -0.000920  -0.000587   -0.001098   -0.000848    0.003523   \n",
      "2       -0.000131  -0.000524  -0.000308   -0.000818   -0.000570    0.004339   \n",
      "3       -0.000483  -0.000368  -0.000367   -0.000662   -0.000345    0.004976   \n",
      "4       -0.000393  -0.000263  -0.000390   -0.000221   -0.000663    0.006093   \n",
      "...           ...        ...        ...         ...         ...         ...   \n",
      "291421   0.000571   0.001179        NaN         NaN         NaN         NaN   \n",
      "291422   0.000300        NaN        NaN         NaN         NaN         NaN   \n",
      "291423   0.000608        NaN        NaN         NaN         NaN         NaN   \n",
      "291424        NaN        NaN        NaN         NaN         NaN         NaN   \n",
      "291425        NaN        NaN        NaN         NaN         NaN         NaN   \n",
      "\n",
      "        return_256n  \n",
      "0          0.017370  \n",
      "1          0.016523  \n",
      "2          0.017233  \n",
      "3          0.017031  \n",
      "4          0.017136  \n",
      "...             ...  \n",
      "291421          NaN  \n",
      "291422          NaN  \n",
      "291423          NaN  \n",
      "291424          NaN  \n",
      "291425          NaN  \n",
      "\n",
      "[291426 rows x 104 columns]\n",
      "Random Forest Accuracy: 0.13635192469553567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.16      0.29      0.21      4028\n",
      "         2.0       0.12      0.10      0.11      5218\n",
      "         3.0       0.11      0.07      0.09      5635\n",
      "         4.0       0.13      0.07      0.09      5726\n",
      "         5.0       0.14      0.10      0.12      5786\n",
      "         6.0       0.22      0.24      0.23      5488\n",
      "         7.0       0.14      0.07      0.09      5691\n",
      "         8.0       0.11      0.07      0.09      5500\n",
      "         9.0       0.11      0.14      0.12      5736\n",
      "        10.0       0.11      0.12      0.12      5213\n",
      "        11.0       0.13      0.32      0.18      4196\n",
      "\n",
      "    accuracy                           0.14     58217\n",
      "   macro avg       0.13      0.14      0.13     58217\n",
      "weighted avg       0.13      0.14      0.13     58217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    #default\n",
    "    ticker = \"ETHUSD\"\n",
    "    frq = \"1\"\n",
    "    target = \"return_8n\"\n",
    "    # parser = argparse.ArgumentParser(description='Process cryptocurrency data.')\n",
    "    # parser.add_argument('ticker', type=str, help='The cryptocurrency ticker symbol (e.g., BTC, ETH)')\n",
    "    # parser.add_argument('frequency', type=int, help='The frequency of data points (e.g., 1 for daily, 7 for weekly)')\n",
    "    # parser.add_argument('target', type=str, help='target return period (e.g return_n8 (return for period n + 8), 2^i')\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    # ticker = args.ticker\n",
    "    # frq = args.frequency\n",
    "    # target = args.target\n",
    "\n",
    "    df = pd.read_csv(f\"data/silver_prices/{ticker}_{frq}_silver.csv\")\n",
    "    print(df)\n",
    "    timestamps = list(df['timestamp'])\n",
    "    X_train, y_train, X_test, y_test = getData(df, target)\n",
    "\n",
    "\n",
    "    model_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # model_path = f'models/{ticker}_{frq}_model_{model_date}.h5'\n",
    "    model_name = f\"{ticker}_{frq}_{target}_{model_date}\"\n",
    "    model_path = \"models/random-forest/\"+model_name+'.joblib'\n",
    "\n",
    "    rf = rfModel(X_train, y_train, X_test, y_test, ticker, frq, target, timestamps, model_name)\n",
    "\n",
    "    rf.fitModelAndPredict()\n",
    "\n",
    "    # getReports(rf.y_test, rf.y_pred, rf.model_name)\n",
    "\n",
    " \n",
    "\n",
    "    # After your model training and before logging the model\n",
    "    # signature = infer_signature(rf.X_train, rf.model.predict(rf.X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import mlflow.sklearn\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import joblib\n",
    "\n",
    "\n",
    "# # Start MLflow run\n",
    "# with mlflow.start_run():\n",
    "#     # Log model parameters, metrics, etc.\n",
    "#     mlflow.log_param(\"n_estimators\", rf.n_estimators)\n",
    "#     mlflow.log_param(\"max_depth\", rf.max_depth)\n",
    "\n",
    "#     # Log the scikit-learn model\n",
    "#     mlflow.sklearn.log_model(rf, \"model\")\n",
    "\n",
    "#     # Optionally save the model locally using joblib\n",
    "#     # model_path = f\"models/{model_name}.joblib\"\n",
    "#     joblib.dump(rf, model_path)\n",
    "#     mlflow.log_artifact(model_path)  # Log the model artifact\n",
    "\n",
    "#     # with mlflow.start_run():\n",
    "#     #     mlflow.keras.log_model(rf.model, \"model\", signature=signature)\n",
    "#     #     # Save the model locally\n",
    "#     #     rf.model.save(f\"models/random-forest/{ticker}_{frq}_{target}_{model_date}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbcf5f2c92c3813cf756da811d2108a7473fed3b7b8c64283edd03593b1ba677"
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 ('crypto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
