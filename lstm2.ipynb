{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm module\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Activation, Input\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from keras.optimizers import Adam\n",
    "import os \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "class Lstm:\n",
    "    def __init__(self, data, ticker, frequency, target, timestamps, model_name, SEQ_LENGTH=100):\n",
    "        self.data = data\n",
    "        self.ticker = ticker\n",
    "        self.frequency = frequency\n",
    "        self.target = target\n",
    "        self.timestamps = timestamps\n",
    "        self.model_name = model_name\n",
    "        self.SEQ_LENGTH = SEQ_LENGTH\n",
    "    \n",
    "    def getData(self):\n",
    "\n",
    "        df = self.data\n",
    "        scaler = MinMaxScaler()\n",
    "        self.scaler = scaler\n",
    "        close_price = df[self.target].values.reshape(-1, 1)\n",
    "\n",
    "        scaled_close = scaler.fit_transform(close_price)\n",
    "        # SEQ_LEN = 100\n",
    "        self.X_train, self.y_train, self.X_test, self.y_test = preprocess(scaled_close, self.SEQ_LENGTH, train_split = 0.95)\n",
    "\n",
    "\n",
    "    # def compileModel(self, opt='adam', loss='mean_squared_error'):\n",
    "    #     #We’re creating a 3 layer LSTM Recurrent Neural Network. We use Dropout with a rate of 20% to combat overfitting during training:\n",
    "\n",
    "    #     # Set your constants\n",
    "    #     DROPOUT = 0.2 \n",
    "    #     WINDOW_SIZE = self.SEQ_LENGTH - 1\n",
    "\n",
    "    #     # Define the model\n",
    "    #     self.model = Sequential()\n",
    "\n",
    "    #     self.model.add(Bidirectional(\n",
    "    #         LSTM(WINDOW_SIZE, return_sequences=True),  # Use LSTM directly\n",
    "    #         input_shape=(WINDOW_SIZE, self.X_train.shape[-1])\n",
    "    #     ))\n",
    "    #     self.model.add(Dropout(rate=DROPOUT))\n",
    "\n",
    "    #     # Add more layers as needed...\n",
    "    #     self.model.add(Dense(1))  # Example output layer\n",
    "\n",
    "    #     # Compile the model\n",
    "    #     self.model.compile(optimizer=opt, loss=loss)\n",
    "\n",
    "    #     # Summary of the model\n",
    "    #     self.model.summary()\n",
    "\n",
    "    #     self.model.add(Activation('linear'))\n",
    "\n",
    "    def compileModel(self, opt='adam', loss='mean_squared_error', learning_rate=0.0001):\n",
    "        # Set your constants\n",
    "        DROPOUT = 0.2 \n",
    "        WINDOW_SIZE = self.SEQ_LENGTH - 1\n",
    "\n",
    "        # Define the model\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # Add Input layer\n",
    "        self.model.add(Input(shape=(WINDOW_SIZE, self.X_train.shape[-1])))\n",
    "\n",
    "        # Add LSTM layer with Bidirectional wrapper\n",
    "        self.model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True)))\n",
    "\n",
    "        # Add Dropout layer\n",
    "        self.model.add(Dropout(rate=DROPOUT))\n",
    "\n",
    "        # Add more layers as needed...\n",
    "        self.model.add(Dense(1))  # Example output layer\n",
    "\n",
    "        # Define the optimizer with the specified learning rate\n",
    "        if opt == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = opt  # Use other optimizers if specified\n",
    "\n",
    "        # Compile the model\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "        # Add Activation layer (if necessary, usually added in the Dense layer for the output)\n",
    "        self.model.add(Activation('linear'))  # This line might not be needed since Activation can be in Dense\n",
    "\n",
    "        # Summary of the model\n",
    "        print(self.model.summary())\n",
    "\n",
    "    # def trainModel(self):\n",
    "\n",
    "    #     self.today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    #     # Set the experiment name (optional)\n",
    "    #     mlflow.set_experiment(f\"{self.ticker}_{self.frequency}_{self.target}_experiment\")\n",
    "\n",
    "    #     BATCH_SIZE = 32\n",
    "\n",
    "    #     with mlflow.start_run():\n",
    "    #         # Compile the model\n",
    "    #         # self.model.compile(\n",
    "    #         #     loss='mean_squared_error',\n",
    "    #         #     optimizer='adam'\n",
    "    #         # )\n",
    "\n",
    "    #         # Log parameters\n",
    "    #         mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    #         mlflow.log_param(\"epochs\", 15)\n",
    "    #         mlflow.log_param(\"optimizer\", \"adam\")\n",
    "\n",
    "    #         history = self.model.fit(\n",
    "    #             self.X_train,\n",
    "    #             self.y_train,\n",
    "    #             epochs=15,\n",
    "    #             batch_size=BATCH_SIZE,\n",
    "    #             shuffle=False,\n",
    "    #             validation_split=0.1\n",
    "    #         )\n",
    "\n",
    "    #         # Log metrics\n",
    "    #         mlflow.log_metric(\"final_loss\", history.history['loss'][-1])\n",
    "    #         mlflow.log_metric(\"final_val_loss\", history.history['val_loss'][-1])\n",
    "\n",
    "    # def saveModel(self):\n",
    "\n",
    "    #     # After your model training and before logging the model\n",
    "    #     signature = infer_signature(self.X_train, self.model.predict(self.X_train))\n",
    "\n",
    "    #     with mlflow.start_run():\n",
    "    #         mlflow.keras.log_model(self.model, \"model\", signature=signature)\n",
    "    #         # Save the model locally\n",
    "    #         self.model.save(f\"models/lstm/{self.ticker}_{self.frequency}_{self.target}_{self.today}.h5\")\n",
    "    def trainModel(self):\n",
    "        self.model_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Set the experiment name (optional)\n",
    "        mlflow.set_experiment(f\"{self.ticker}_{self.frequency}_{self.target}_{self.model_date}_lstm_experiment\")\n",
    "\n",
    "        BATCH_SIZE = 32\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "            mlflow.log_param(\"epochs\", 15)\n",
    "            mlflow.log_param(\"optimizer\", \"adam\")\n",
    "\n",
    "            # Train the model\n",
    "            history = self.model.fit(\n",
    "                self.X_train,\n",
    "                self.y_train,\n",
    "                epochs=15,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                validation_split=0.1\n",
    "            )\n",
    "\n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"final_loss\", history.history['loss'][-1])\n",
    "            mlflow.log_metric(\"final_val_loss\", history.history['val_loss'][-1])\n",
    "\n",
    "    def saveModel(self):\n",
    "        # Predict on validation/test data\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        # Convert predictions to class labels if necessary\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int)  # Example for binary classification\n",
    "\n",
    "        # Calculate accuracy (or any other relevant metrics)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred_classes)\n",
    "\n",
    "        # Create a model directory\n",
    "        model_name = f\"{self.ticker}_{self.frequency}_{self.target}_{self.model_date}\"\n",
    "        model_dir = f\"models/lstm/{model_name}\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        # Save the model as an .h5 file\n",
    "        model_path = os.path.join(model_dir, f\"{model_name}.h5\")\n",
    "        self.model.save(model_path)\n",
    "\n",
    "        # Log the model and metrics with MLflow\n",
    "        with mlflow.start_run():\n",
    "            # mlflow.keras.log_model(self.model, \"model\")\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "            # Save metrics to a text file\n",
    "            metrics_path = os.path.join(model_dir, \"metrics.txt\")\n",
    "            with open(metrics_path, \"w\") as f:\n",
    "                f.write(f\"Final Accuracy: {accuracy}\\n\")\n",
    "                f.write(\"Classification Report:\\n\")\n",
    "                f.write(classification_report(self.y_test, y_pred_classes))\n",
    "\n",
    "        print(f'LSTM Model saved to {model_path} with accuracy: {accuracy}')\n",
    "\n",
    "    def predictAndUnscale(self):\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        # Select the last timestep\n",
    "        # Assuming y_hat has shape (batch_size, timesteps, features)\n",
    "        # Select the last timestep for predictions\n",
    "        self.y_pred_last_timestamp = self.y_pred[:, -1, :]  # Make sure y_hat has the expected shape\n",
    "\n",
    "        # Inverse transform the predictions\n",
    "        self.y_pred_inverse = self.scaler.inverse_transform(self.y_pred_last_timestamp)\n",
    "\n",
    "        # Assuming y_test is a 2D array (if you're using a sequence of values)\n",
    "        # If y_test was reshaped correctly when prepared, do this:\n",
    "        self.y_test_inverse = self.scaler.inverse_transform(self.y_test)\n",
    "\n",
    "        if self.y_test.ndim == 3:\n",
    "            self.y_test_last_timestep = self.y_test[:, -1, :]  # Only if y_test is 3D\n",
    "            self.y_test_inverse = self.scaler.inverse_transform(self.y_test_last_timestep)\n",
    "\n",
    "    def setModel(self, model):\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "\n",
    "def to_sequences(data, seq_len):\n",
    "    d = []\n",
    "\n",
    "    for index in range(len(data) - seq_len):\n",
    "        d.append(data[index: index + seq_len])\n",
    "\n",
    "    return np.array(d)\n",
    "\n",
    "def preprocess(data_raw, seq_len, train_split):\n",
    "\n",
    "    data = to_sequences(data_raw, seq_len)\n",
    "\n",
    "    num_train = int(train_split * data.shape[0])\n",
    "\n",
    "    X_train = data[:num_train, :-1, :]\n",
    "    y_train = data[:num_train, -1, :]\n",
    "\n",
    "    X_test = data[num_train:, :-1, :]\n",
    "    y_test = data[num_train:, -1, :]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           timestamp     open     high      low    close     volume  \\\n",
      "136824  1.718736e+09  3414.42  3414.42  3414.32  3414.32   0.221110   \n",
      "136825  1.718736e+09  3413.68  3413.68  3413.68  3413.68   1.432814   \n",
      "136826  1.718736e+09  3413.68  3413.68  3410.28  3410.28  13.196809   \n",
      "136827  1.718736e+09  3410.60  3410.60  3407.70  3407.70   0.579290   \n",
      "136828  1.718736e+09  3407.71  3407.71  3407.71  3407.71   5.829947   \n",
      "...              ...      ...      ...      ...      ...        ...   \n",
      "273642  1.727740e+09  2597.52  2598.13  2597.52  2598.13   0.714424   \n",
      "273643  1.727741e+09  2598.64  2600.99  2598.64  2600.99   0.985735   \n",
      "273644  1.727741e+09  2601.93  2601.93  2601.93  2601.93   0.105847   \n",
      "273645  1.727741e+09  2602.25  2603.48  2602.24  2603.48   5.066109   \n",
      "273646  1.727741e+09  2602.97  2602.97  2602.97  2602.97   0.323397   \n",
      "\n",
      "                   0            1          2            3  ...  \\\n",
      "136824  1.718736e+09  3416.984350  3411.1750  3405.365650  ...   \n",
      "136825  1.718736e+09  3416.769279  3411.1085  3405.447721  ...   \n",
      "136826  1.718736e+09  3416.615858  3410.9900  3405.364142  ...   \n",
      "136827  1.718736e+09  3416.487547  3410.7420  3404.996453  ...   \n",
      "136828  1.718736e+09  3416.315462  3410.4950  3404.674538  ...   \n",
      "...              ...          ...        ...          ...  ...   \n",
      "273642  1.727740e+09  2600.925341  2590.9780  2581.030659  ...   \n",
      "273643  1.727741e+09  2602.381576  2591.5585  2580.735424  ...   \n",
      "273644  1.727741e+09  2603.792235  2592.0610  2580.329765  ...   \n",
      "273645  1.727741e+09  2605.398057  2592.6635  2579.928943  ...   \n",
      "273646  1.727741e+09  2606.740055  2593.3120  2579.883945  ...   \n",
      "\n",
      "        hilberttransformdominantcycleperiod_1  \\\n",
      "136824                              30.944137   \n",
      "136825                              30.942550   \n",
      "136826                              30.369458   \n",
      "136827                              29.349382   \n",
      "136828                              28.071809   \n",
      "...                                       ...   \n",
      "273642                              35.615103   \n",
      "273643                              34.508636   \n",
      "273644                              33.064634   \n",
      "273645                              31.597963   \n",
      "273646                              30.351444   \n",
      "\n",
      "        hilberttransformdominantcyclephase_1  hilberttransformtrendmode_1  \\\n",
      "136824                             10.635640                          0.0   \n",
      "136825                             22.263266                          0.0   \n",
      "136826                             38.262889                          0.0   \n",
      "136827                             54.488155                          0.0   \n",
      "136828                             68.077412                          0.0   \n",
      "...                                      ...                          ...   \n",
      "273642                             43.999479                          0.0   \n",
      "273643                             54.711203                          0.0   \n",
      "273644                             72.502134                          0.0   \n",
      "273645                             89.446298                          0.0   \n",
      "273646                            113.402863                          0.0   \n",
      "\n",
      "        return_2n  return_4n  return_8n  return_16n  return_32n  return_64n  \\\n",
      "136824  -0.001183  -0.001936  -0.002601   -0.003796   -0.005325   -0.006215   \n",
      "136825  -0.001752  -0.001922  -0.002411   -0.003099   -0.005657   -0.007467   \n",
      "136826  -0.000754  -0.000930  -0.002120   -0.003284   -0.004809   -0.003897   \n",
      "136827  -0.000170  -0.000678  -0.001881   -0.003821   -0.003477   -0.001159   \n",
      "136828  -0.000176  -0.000666  -0.001963   -0.004959   -0.003337   -0.002145   \n",
      "...           ...        ...        ...         ...         ...         ...   \n",
      "273642   0.001463   0.001863        NaN         NaN         NaN         NaN   \n",
      "273643   0.000957        NaN        NaN         NaN         NaN         NaN   \n",
      "273644   0.000400        NaN        NaN         NaN         NaN         NaN   \n",
      "273645        NaN        NaN        NaN         NaN         NaN         NaN   \n",
      "273646        NaN        NaN        NaN         NaN         NaN         NaN   \n",
      "\n",
      "        return_256n  \n",
      "136824     0.017570  \n",
      "136825     0.018025  \n",
      "136826     0.018746  \n",
      "136827     0.019741  \n",
      "136828     0.019500  \n",
      "...             ...  \n",
      "273642          NaN  \n",
      "273643          NaN  \n",
      "273644          NaN  \n",
      "273645          NaN  \n",
      "273646          NaN  \n",
      "\n",
      "[136823 rows x 104 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 17:48:29.871723: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-11-02 17:48:29.871752: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-11-02 17:48:29.871757: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-11-02 17:48:29.871940: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-02 17:48:29.871951: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m198\u001b[0m)        │        \u001b[38;5;34m79,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m198\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │           \u001b[38;5;34m199\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,191</span> (313.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,191\u001b[0m (313.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,191</span> (313.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,191\u001b[0m (313.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/02 17:48:30 INFO mlflow.tracking.fluent: Experiment with name 'ETHUSD_1_return_8n_2024-11-02_lstm_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 17:48:30.548134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3654/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 58ms/step - loss: 0.0164 - val_loss: 6.3517e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m3654/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 59ms/step - loss: 8.7251e-04 - val_loss: 1.1213e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m3654/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 60ms/step - loss: 4.2710e-04 - val_loss: 7.4598e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m3654/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 60ms/step - loss: 3.4911e-04 - val_loss: 7.4345e-05\n",
      "Epoch 5/15\n",
      "\u001b[1m3654/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 61ms/step - loss: 3.0634e-04 - val_loss: 7.3730e-05\n",
      "Epoch 6/15\n",
      "\u001b[1m3654/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 61ms/step - loss: 2.7303e-04 - val_loss: 7.9748e-05\n",
      "Epoch 7/15\n",
      "\u001b[1m2419/3654\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 59ms/step - loss: 2.3083e-04"
     ]
    }
   ],
   "source": [
    "ticker = \"ETHUSD\"\n",
    "frq = \"1\"\n",
    "target = \"return_8n\"\n",
    "# parser = argparse.ArgumentParser(description='Process cryptocurrency data.')\n",
    "# parser.add_argument('ticker', type=str, help='The cryptocurrency ticker symbol (e.g., BTC, ETH)')\n",
    "# parser.add_argument('frequency', type=int, help='The frequency of data points (e.g., 1 for daily, 7 for weekly)')\n",
    "# parser.add_argument('target', type=str, help='target return period (e.g return_n8 (return for period n + 8), 2^i')\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# ticker = args.ticker\n",
    "# frq = args.frequency\n",
    "# target = args.target\n",
    "\n",
    "df = pd.read_csv(f\"data/silver_prices/{ticker}_{frq}_silver.csv\")\n",
    "\n",
    "df = df[-int((len(df)/2)):]\n",
    "\n",
    "print(df)\n",
    "timestamps = list(df['timestamp'])\n",
    "model_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "#\n",
    "model_name = f\"{ticker}_{frq}_{target}_{model_date}\"\n",
    "model_path = \"models/lstm/\"+model_name\n",
    "\n",
    "lstm = Lstm(df, ticker, frq, target, timestamps, model_name, SEQ_LENGTH=100)\n",
    "\n",
    "lstm.getData()\n",
    "lstm.compileModel()\n",
    "lstm.trainModel()\n",
    "# lstm.saveModel()\n",
    "# lstm.predictAndUnscale()\n",
    "# preds = lstm.y_pred_inverse\n",
    "# real = lstm.y_test_inverse\n",
    "# data = {\n",
    "#     \"timestamps\": timestamps,\n",
    "#     \"predicted\":preds,\n",
    "#     \"real\":real,\n",
    "# }\n",
    "# result = pd.DataFrame(data)\n",
    "# result.to_csv(f\"models/model-output/lstm/{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lstm\u001b[38;5;241m.\u001b[39msaveModel()\n\u001b[1;32m      2\u001b[0m lstm\u001b[38;5;241m.\u001b[39mpredictAndUnscale()\n\u001b[1;32m      3\u001b[0m preds \u001b[38;5;241m=\u001b[39m lstm\u001b[38;5;241m.\u001b[39my_pred_inverse\n",
      "Cell \u001b[0;32mIn[14], line 183\u001b[0m, in \u001b[0;36mLstm.saveModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m (y_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)  \u001b[38;5;66;03m# Example for binary classification\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Calculate accuracy (or any other relevant metrics)\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, y_pred_classes)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Create a model directory\u001b[39;00m\n\u001b[1;32m    186\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrequency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/crypto/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/crypto/lib/python3.11/site-packages/sklearn/metrics/_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/crypto/lib/python3.11/site-packages/sklearn/metrics/_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m    103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m~/miniforge3/envs/crypto/lib/python3.11/site-packages/sklearn/utils/multiclass.py:398\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    396\u001b[0m     data \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39many(data \u001b[38;5;241m!=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(data, \u001b[38;5;28mint\u001b[39m)):\n\u001b[0;32m--> 398\u001b[0m         _assert_all_finite(data, input_name\u001b[38;5;241m=\u001b[39minput_name)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/crypto/lib/python3.11/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    124\u001b[0m     X,\n\u001b[1;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    130\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/crypto/lib/python3.11/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "lstm.saveModel()\n",
    "\n",
    "\n",
    "# lstm.predictAndUnscale()\n",
    "# preds = lstm.y_pred_inverse\n",
    "# real = lstm.y_test_inverse\n",
    "# data = {\n",
    "#     \"timestamps\": timestamps,\n",
    "#     \"predicted\":preds,\n",
    "#     \"real\":real,\n",
    "# }\n",
    "# result = pd.DataFrame(data)\n",
    "# result.to_csv(f\"models/model-output/lstm/{model_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbcf5f2c92c3813cf756da811d2108a7473fed3b7b8c64283edd03593b1ba677"
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 ('crypto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
